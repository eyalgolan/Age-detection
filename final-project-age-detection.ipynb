{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis is the implementation of [Age and Gender Classification by Gil Levi and Tal Hassner](https://talhassner.github.io/home/projects/cnn_agegender/CVPR2015_CNN_AgeGenderEstimation.pdf) using PyTorch as the deep learning framework.\n\nThe network proposed in the paper has five convolutional layers and three fully connected layers.","metadata":{"id":"7QQe6I3yhCY_"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"UkNgiJoSm87s"}},{"cell_type":"code","source":"import torch\nimport torch.autograd.variable as Variable\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.utils as utils\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom shutil import copyfile\nimport pandas as pd\nimport seaborn as sns","metadata":{"id":"BRaqXIPonB8j","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing dataloaders","metadata":{"id":"0_z6Q972xi32"}},{"cell_type":"markdown","source":"## Data\n\nWe use the Adience dataset with consists of unfiltered faces.","metadata":{"id":"s_KtxziRPrVI"}},{"cell_type":"markdown","source":"## Folds\n\nAll five folds used in this paper are present [here](https://github.com/GilLevi/AgeGenderDeepLearning/tree/master/Folds/train_val_txt_files_per_fold). We have uploaded them to kaggle in order to use them more easily.\n","metadata":{"id":"88F5gWj5o4bh"}},{"cell_type":"markdown","source":"## Data loading","metadata":{"id":"2VtoAJghnpLn"}},{"cell_type":"code","source":"PATH_TO_FOLDS= \"../input/train-val-txt-files-per-fold/train_val_txt_files_per_fold/\"\nPATH_TO_DATA = \"../input/adiencegender/AdienceGender\"\nPATH_TO_IMAGE_FOLDERS = PATH_TO_DATA + \"/aligned\"","metadata":{"id":"squb12xguXqd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating a Dataset class\n\nWe create a class **`AdienceDataset`** that extends **`Dataset`**. This class helps us in feeding the input data to the network in minibatches.","metadata":{"id":"O2Czi4va4QKo"}},{"cell_type":"code","source":"class AdienceDataset(Dataset):\n    \n    def __init__(self, txt_file, root_dir, transform):\n        self.txt_file = txt_file\n        self.root_dir = root_dir\n        self.transform = transform\n        self.data = self.read_from_txt_file()\n    \n    def __len__(self):\n        return len(self.data)\n\n    def read_from_txt_file(self):\n        data = []\n        f = open(self.txt_file)\n        for line in f.readlines():\n            image_file, label = line.split()\n            label = int(label)\n            if 'gender' in self.txt_file:\n                label += 8\n            data.append((image_file, label))\n        return data\n    \n    def __getitem__(self, idx):\n        img_name, label = self.data[idx]\n        image = Image.open(self.root_dir + '/' + img_name)\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return {\n            'image': image,\n            'label': label\n        }         ","metadata":{"id":"BiUufbSinr1K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transforms\nEvery image is first resized to a `256x256` image and then cropped to a `227x227` image before being fed to the network.\n\n**`transforms_list`** is the list of transforms we would like to apply to the input data. Apart from training the neural network without any transformations, we can also train the network using the following transforms (also called as data augmentation techniques):\n*   random horizontal flip\n*   random crop and random horizontal flip\n\nWe don't perform any transformation on the images during validation and testing.\n","metadata":{"id":"WAx-8hZNsXFM"}},{"cell_type":"code","source":"transforms_list = [\n    transforms.Resize(256),\n    transforms.CenterCrop(227),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.RandomCrop(227)\n]\n\ntransforms_dict = {\n    'train': {\n        0: list(transforms_list[i] for i in [0, 1, 3]),        # no transformation\n        1: list(transforms_list[i] for i in [0, 1, 2, 3]),     # random horizontal flip\n        2: list(transforms_list[i] for i in [0, 4, 2, 3])      # random crop and random horizontal flip\n    },\n    'val': {\n        0: list(transforms_list[i] for i in [0, 1, 3])\n    },\n    'test': {\n        0: list(transforms_list[i] for i in [0, 1, 3])\n    }\n}","metadata":{"id":"_wMCsfG1sY4s","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader\nThe **`DataLoader`** class in PyTorch helps us iterate through the dataset. This is where we input **`minibatch_size`** to our algorithm.","metadata":{"id":"iURni95m4sGW"}},{"cell_type":"code","source":"def get_dataloader(source, fold, transform_index, minibatch_size):\n    \"\"\"\n    Args:\n        source: A string. Equals either \"train\", \"val\", or \"test\".\n        fold: An integer. Lies in the range [0, 4] as there are five folds present.\n        transform_index: An integer. The transforms in the list correesponding\n            to this index in the dictionary will be applied on the images.\n        minibatch_size: An integer.\n\n    Returns:\n        An instance of the DataLoader class.\n    \"\"\"\n    path_to_folds= \"../input/train-val-txt-files-per-fold/train_val_txt_files_per_fold/\"\n    path_to_data = \"../input/adiencegender/AdienceGender\"\n    root_dir = path_to_data + \"/aligned\"\n    \n    txt_file = f'{path_to_folds}/test_fold_is_{fold}/age_{source}.txt'\n    transformed_dataset = AdienceDataset(txt_file, root_dir,\n                                         transforms.Compose(transforms_dict[s][transform_index]))\n    dataloader = DataLoader(transformed_dataset, batch_size=minibatch_size, shuffle=True, num_workers=4)\n    \n    return dataloader","metadata":{"id":"ox_PryLS4u2x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{"id":"9lrstEuSm1qH"}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"o9feSnLcFq2q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the network\nThis is the network as described in the [paper](https://talhassner.github.io/home/projects/cnn_agegender/CVPR2015_CNN_AgeGenderEstimation.pdf).","metadata":{"id":"SZh1psZ6mY6d"}},{"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 96, 7, stride = 4, padding = 1)\n        self.pool1 = nn.MaxPool2d(3, stride = 2, padding = 1)\n        self.norm1 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n        \n        self.conv2 = nn.Conv2d(96, 256, 5, stride = 1, padding = 2)\n        self.pool2 = nn.MaxPool2d(3, stride = 2, padding = 1)\n        self.norm2 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n        \n        self.conv3 = nn.Conv2d(256, 384, 3, stride = 1, padding = 1)\n        self.pool3 = nn.MaxPool2d(3, stride = 2, padding = 1)\n        self.norm3 = nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75)\n        \n        self.fc1 = nn.Linear(18816, 512)\n        self.dropout1 = nn.Dropout(0.5)\n\n        self.fc2 = nn.Linear(512, 512)\n        self.dropout2 = nn.Dropout(0.5)\n  \n        self.fc3 = nn.Linear(512, 10)\n    \n        self.apply(weights_init)\n\n    \n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x))\n        x = self.pool1(x)\n        x = self.norm1(x)\n\n        x = F.leaky_relu(self.conv2(x))\n        x = self.pool2(x)\n        x = self.norm2(x)\n      \n        x = F.leaky_relu(self.conv3(x))\n        x = self.pool3(x)\n        x = self.norm3(x)\n      \n        x = x.view(-1, 18816)\n        \n        x = self.fc1(x)\n        x = F.leaky_relu(x)\n        x = self.dropout1(x)\n      \n        x = self.fc2(x)\n        x = F.leaky_relu(x)\n        x = self.dropout2(x)\n      \n        x = F.log_softmax(self.fc3(x), dim=1)\n  \n        return x","metadata":{"id":"pd91hyHvmhYP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        nn.init.normal_(m.weight, mean=0, std=1e-2)","metadata":{"id":"uaI0Bs-Rxio-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss()","metadata":{"id":"FrLA7cfxj4JE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the network\nWe compute and save the train and validation loss after every **`epoch`**. \n\nWe decrease the learning by a tenth after 10,000 iterations using the **`MultiStepLR`** class of PyTorch.","metadata":{"id":"G5NPiENkmpYl"}},{"cell_type":"code","source":"def train(net, train_dataloader, validation_dataloader, optimizer, scheduler):\n    \"\"\"\n    Args:\n        net: An instance of PyTorch's Net class.\n        train_dataloader: An instance of PyTorch's Dataloader class.\n        epochs: An integer.\n        validation_dataloader: An instance of PyTorch's Dataloader class.\n        optimizer:\n        scheduler:\n    \n    Returns:\n        net: An instance of PyTorch's Net class. The trained network.\n        training_loss: represents the training loss.\n        validation_loss:  represents the validation loss.\n    \"\"\"\n    net.train()\n    \n    checkpoint = 0\n    iteration = 0\n    running_loss = 0\n    for i, batch in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        optimizer.step()\n        scheduler.step()\n        images, labels = batch['image'].to(device), batch['label'].to(device)\n        outputs = net(images)\n        loss = criterion(outputs, labels)\n        running_loss += float(loss.item())\n        loss.backward()\n        optimizer.step()\n    \n    training_loss = running_loss / (i+1)\n    validation_loss = validate(net, validation_dataloader)\n    return net, training_loss, validation_loss","metadata":{"id":"NnkM7TgymrED","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation\nWe evaluate the performance (in terms of loss) of the trained network on validation set.","metadata":{"id":"x7WndciFmv0C"}},{"cell_type":"code","source":"def validate(net, dataloader):\n    net.train()\n    total_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(dataloader):\n            images, labels = batch['image'].to(device), batch['label'].to(device)\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n            total_loss += float(loss.item())\n\n    return total_loss/(i+1)","metadata":{"id":"8Es1uGKQnK9D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing\nWe evaluate the performance (in terms of accuracy) of the trained network on the test set.","metadata":{"id":"gAto0iO4zPLw"}},{"cell_type":"code","source":"def test(net, dataloader):\n    result = {\n        'exact_match': 0,\n        'total': 0,\n        'one_off_match': 0\n    }\n\n    with torch.no_grad():\n        net.eval()\n        for i, batch in enumerate(dataloader):\n            images, labels = batch['image'].to(device), batch['label'].to(device)\n            outputs = net(images)\n            outputs = torch.tensor(list(map(lambda x: torch.max(x, 0)[1], outputs))).to(device)\n            result['total'] += len(outputs)\n            result['exact_match'] += sum(outputs == labels).item()\n            result['one_off_match'] += (sum(outputs==labels) + sum(outputs==labels-1) + sum(outputs==labels+1)).item()\n\n    return result['total'], result['exact_match'], result['one_off_match']","metadata":{"id":"fCUCNrL0zR3n","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Execution","metadata":{"id":"hl1owOOw0ZeU"}},{"cell_type":"markdown","source":"## Hyperparameters\nThe **`minibatch_size`** and **`lr`** are pulled from the paper, **`num_epochs`** is set empirically. ","metadata":{}},{"cell_type":"code","source":"lr = 0.0001  # initial learning rate\nepochs = 40\nminibatch_size = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Running the model with different folds and transformations","metadata":{}},{"cell_type":"markdown","source":"##### We run each of the folds 0, 1, 2, 3, 4 - each with each of the transormations options for the train","metadata":{}},{"cell_type":"code","source":"folds = [0, 1, 2, 3, 4]\ntrain_transform_indexs = [0, 1, 2]\ntest_results_by_fold_transform_epoch = {}\n\nfor fold in folds:\n    for train_transform_index in train_transform_indexs:\n        print(\"=\" * 30)\n        print(\"Running the model with: fold: \" + str(fold) + \", train transform: \" + str(train_transform_index))\n        \n        # setup\n        criterion = nn.NLLLoss().to(device)\n        new_model= Net().to(device)\n        lr = 0.0001  # initial learning rate\n        optimizer = optim.Adam(new_model.parameters(), lr)\n        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10000])\n\n        test_results_by_fold_transform_epoch[(fold, train_transform_index)] = {'exact_match': [],\n                                                                               'total': [],\n                                                                               'one_off_match': []}\n        training_loss = []\n        validation_loss = []\n        train_loader = get_dataloader('train', fold, train_transform_index, minibatch_size)\n        validation_loader = get_dataloader('val', fold, 0, minibatch_size)\n        test_loader = get_dataloader('test', fold, 0, minibatch_size)\n        \n        # runing a train and a test for each epoch, collecting and printing the results\n        for epoch in range(epochs):\n                new_model, curr_training_loss, curr_validation_loss = train(new_model, train_loader, validation_loader, optimizer, scheduler)\n                training_loss.append(curr_training_loss)\n                validation_loss.append(curr_validation_loss)\n                total, exact_match, one_off_match = test(new_model, test_loader)\n                test_results_by_fold_transform_epoch[(fold, train_transform_index)]['total'].append(total)\n                test_results_by_fold_transform_epoch[(fold, train_transform_index)]['exact_match'].append(exact_match)\n                test_results_by_fold_transform_epoch[(fold, train_transform_index)]['one_off_match'].append(one_off_match)\n                print(\"EPOCH: \" + str(epoch) + \" | Train and Validate: training_error: \" + str(training_loss[-1]) + \", validation_error:\" + str(validation_loss[-1]) + \n                      \" | Test: total: \" + str(total) + \", exact match: \" + str(exact_match) + \", one off match: \" + str(one_off_match))\n        \n        # plotting the results\n        plt.figure(figsize=(12,6))\n\n        plt.xticks(range(epochs))\n        plt.plot(training_loss, label='training_loss')\n        plt.plot(validation_loss, label='validation_loss')\n        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n                   ncol=2, mode=\"expand\", borderaxespad=0.)\n        plt.xlabel('Epochs')\n        plt.ylabel('loss')\n        plt.show()\n\n        test_results = test_results_by_fold_transform_epoch[(fold, train_transform_index)]\n\n        result_dataframe = pd.DataFrame(\n            {'total': test_results['total'],\n             'one_off_match': test_results['one_off_match'],\n             'exact_match': test_results['exact_match']})\n        sns.set(rc={'figure.figsize':(12,6)})\n        sns.lineplot(data=result_dataframe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{"id":"PqPEPILSzrKW"}}]}